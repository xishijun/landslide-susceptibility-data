# -*- coding: utf-8 -*-
"""
æ»‘å¡é¢„æµ‹æ ·æœ¬å¹³è¡¡ç³»ç»Ÿ v4.3ï¼ˆæ—¶é—´å®Œå…¨åŒ¹é…ç‰ˆï¼‰
è´Ÿæ ·æœ¬ä¸æ­£æ ·æœ¬æ—¶é—´åˆ†å¸ƒå®Œå…¨ä¸€è‡´ï¼Œæ¨¡æ‹ŸåŒåœºé™é›¨æ¡ä»¶
"""
import os
import pandas as pd
import geopandas as gpd
import numpy as np
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cfeature
from geopy.distance import geodesic
import warnings
warnings.filterwarnings('ignore')

# æŒ‡å®šä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# ---------------------------- é…ç½®å‚æ•° ----------------------------
BASE_DIR = r'E:/æ€€åŒ–å¸‚åœ°è´¨ç¾å®³æ”»å…³/æ ·æœ¬æ•°æ®/å…¨å¸‚å«é™é›¨æ—¶é—´æ ·æœ¬'
DATA_PATH = r'E:/æ€€åŒ–å¸‚åœ°è´¨ç¾å®³æ”»å…³/é™ˆçº¢ä¸“æä¾›æ•°æ®/å…¨å¸‚æ­£æ ·æœ¬.csv' 
BOUNDARY_PATH = 'E:/æ€€åŒ–å¸‚åœ°è´¨ç¾å®³æ”»å…³/çº¦æŸæ•°æ®/æ€€åŒ–å¸‚è¡Œæ”¿è¾¹ç•Œ.shp'
VULNERABILITY_PATH = 'E:/æ€€åŒ–å¸‚åœ°è´¨ç¾å®³æ”»å…³/çº¦æŸæ•°æ®/æ˜“å‘æ€§åˆ†åŒº.shp' 
MIN_DISTANCE = 100  # æœ€å°æ ·æœ¬é—´è·(ç±³)
RANDOM_STATE = 42   # éšæœºç§å­
TARGET_RATIOS = [2,3,4,5,8,10]  # åªå¤„ç†1:1æ¯”ä¾‹

# åŸºæœ¬å­—æ®µ
BASIC_COLUMNS = ['id', 'lon', 'lat', 'æ—¥æœŸ', 'target']

# ---------------------------- æ ¸å¿ƒå‡½æ•° ----------------------------
def load_data():
    """æ•°æ®åŠ è½½ä¸éªŒè¯"""
    data = pd.read_csv(DATA_PATH, encoding='gbk', parse_dates=['æ—¥æœŸ'])
    admin = gpd.read_file(BOUNDARY_PATH) 
    vulnerability = gpd.read_file(VULNERABILITY_PATH)
    
    # æ£€æŸ¥åŸºæœ¬å­—æ®µ
    missing_cols = [c for c in BASIC_COLUMNS if c not in data.columns]
    if missing_cols:
        raise ValueError(f"ç¼ºå¤±å¿…è¦å­—æ®µ: {missing_cols}")
    
    return data, admin, vulnerability


def analyze_time_distribution(data):
    """åˆ†ææ­£æ ·æœ¬çš„æ—¶é—´åˆ†å¸ƒç‰¹å¾"""
    print("\nğŸ“Š æ­£æ ·æœ¬æ—¶é—´åˆ†å¸ƒåˆ†æ:")
    
    # ç¡®ä¿æ—¥æœŸä¸ºdatetimeç±»å‹
    data['æ—¥æœŸ'] = pd.to_datetime(data['æ—¥æœŸ'])
    
    # æå–æ—¶é—´ç‰¹å¾
    data['å¹´'] = data['æ—¥æœŸ'].dt.year
    data['æœˆ'] = data['æ—¥æœŸ'].dt.month
    data['å­£èŠ‚'] = data['æ—¥æœŸ'].dt.month % 12 // 3 + 1  # 1:æ˜¥, 2:å¤, 3:ç§‹, 4:å†¬
    data['æ˜ŸæœŸ'] = data['æ—¥æœŸ'].dt.dayofweek  # 0:å‘¨ä¸€, 6:å‘¨æ—¥
    
    # ç»Ÿè®¡å¹´åˆ†å¸ƒ
    year_dist = data['å¹´'].value_counts().sort_index()
    print(f"  å¹´ä»½åˆ†å¸ƒ: {dict(year_dist)}")
    
    # ç»Ÿè®¡æœˆåˆ†å¸ƒ
    month_dist = data['æœˆ'].value_counts().sort_index()
    print(f"  æœˆä»½åˆ†å¸ƒ: {dict(month_dist)}")
    
    # ç»Ÿè®¡å­£èŠ‚åˆ†å¸ƒ
    season_labels = {1: 'æ˜¥å­£', 2: 'å¤å­£', 3: 'ç§‹å­£', 4: 'å†¬å­£'}
    season_dist = data['å­£èŠ‚'].value_counts().sort_index()
    season_dist_named = {season_labels[k]: v for k, v in season_dist.items()}
    print(f"  å­£èŠ‚åˆ†å¸ƒ: {season_dist_named}")
    
    # ç»Ÿè®¡æ˜ŸæœŸåˆ†å¸ƒ
    week_labels = {0: 'å‘¨ä¸€', 1: 'å‘¨äºŒ', 2: 'å‘¨ä¸‰', 3: 'å‘¨å››', 4: 'å‘¨äº”', 5: 'å‘¨å…­', 6: 'å‘¨æ—¥'}
    week_dist = data['æ˜ŸæœŸ'].value_counts().sort_index()
    week_dist_named = {week_labels[k]: v for k, v in week_dist.items()}
    print(f"  æ˜ŸæœŸåˆ†å¸ƒ: {week_dist_named}")
    
    # è®¡ç®—æ—¶é—´åˆ†å¸ƒç»Ÿè®¡é‡
    time_features = {
        'year_dist': {int(k): int(v) for k, v in year_dist.to_dict().items()},
        'month_dist': {int(k): int(v) for k, v in month_dist.to_dict().items()},
        'season_dist': {int(k): int(v) for k, v in season_dist.to_dict().items()},
        'week_dist': {int(k): int(v) for k, v in week_dist.to_dict().items()},
        'date_list': data['æ—¥æœŸ'].tolist(),  # ä¿å­˜æ‰€æœ‰æ­£æ ·æœ¬æ—¥æœŸ
        'date_range': (data['æ—¥æœŸ'].min(), data['æ—¥æœŸ'].max()),
        'total_samples': len(data)
    }
    
    return time_features


def filter_in_boundary(data, admin, vulnerability):
    """ç©ºé—´è¾¹ç•Œè¿‡æ»¤å’Œæ˜“å‘æ€§æŒ‡æ•°è¿‡æ»¤"""
    gdf = gpd.GeoDataFrame(
        data,
        geometry=gpd.points_from_xy(data['lon'], data['lat']),
        crs=admin.crs
    )
    # ç©ºé—´è¾¹ç•Œè¿‡æ»¤
    boundary_filtered = gpd.sjoin(gdf, admin, how='inner', predicate='within').drop(columns=['index_right'])
    # æ˜“å‘æ€§æŒ‡æ•°è¿‡æ»¤ï¼Œåªä¿ç•™fenjiä¸º2å’Œ3çš„æ•°æ®
    vulnerability_filtered = vulnerability[(vulnerability['fenji'] == 2) | (vulnerability['fenji'] == 3)]
    if boundary_filtered.crs != vulnerability_filtered.crs:
        vulnerability_filtered = vulnerability_filtered.to_crs(boundary_filtered.crs)
    final_filtered = gpd.sjoin(boundary_filtered, vulnerability_filtered, how='inner', predicate='within').drop(columns=['index_right'])
    return final_filtered


def check_min_distance(new_points, existing_points, min_dist):
    """ç²¾ç¡®è·ç¦»æ£€æŸ¥"""
    for new_pt in new_points:
        for exist_pt in existing_points:
            try:
                if geodesic((new_pt[1], new_pt[0]), (exist_pt[1], exist_pt[0])).m < min_dist:
                    return False
            except:
                continue
    return True


def balance_samples(valid_pos, admin, vulnerability, time_features, ratio=1):
    """å®Œå…¨æ—¶é—´åŒ¹é…çš„å¹³è¡¡æ ·æœ¬ç”Ÿæˆ"""
    # ================= åˆå§‹åŒ–æ ¡éªŒ =================
    if valid_pos.empty:
        raise ValueError("æ­£æ ·æœ¬æ•°æ®ä¸ºç©º")
    if 'geometry' not in admin.columns:
        admin = admin.set_geometry('geometry')
    if admin.crs != vulnerability.crs:
        vulnerability = vulnerability.to_crs(admin.crs)
    
    n_pos = len(valid_pos)  # è·å–æ­£æ ·æœ¬æ•°é‡
    n_neg = int(n_pos * ratio)  # æ ¹æ®æ¯”ä¾‹è®¡ç®—è´Ÿæ ·æœ¬æ•°é‡
    
    # ================= ç”Ÿæˆå€™é€‰è´Ÿæ ·æœ¬ç‚¹ =================
    vul_zones = vulnerability[vulnerability['fenji'].isin([2, 3])]
    
    if vul_zones.empty:
        raise ValueError("åœ¨æ˜“å‘æ€§åˆ†åŒºä¸­æœªæ‰¾åˆ°ç­‰çº§ä¸º2æˆ–3çš„åŒºåŸŸ")
    
    candidate_points = [] 

    # ç”Ÿæˆæ›´å¤šå€™é€‰ç‚¹ä»¥ç¡®ä¿è¶³å¤Ÿæ•°é‡
    np.random.seed(RANDOM_STATE)
    max_attempts = n_neg * 20  # å¢åŠ å°è¯•æ¬¡æ•°
    attempts = 0
    
    while len(candidate_points) < n_neg * 5 and attempts < max_attempts:  # ç”Ÿæˆ5å€å€™é€‰ç‚¹
        zone = vul_zones.sample(1).geometry.iloc[0]
        if zone.is_empty:
            attempts += 1
            continue
            
        minx, miny, maxx, maxy = zone.bounds
        lon = np.random.uniform(minx, maxx)
        lat = np.random.uniform(miny, maxy)
        point = gpd.points_from_xy([lon], [lat])[0]
        
        # æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨åŒºåŸŸå†…
        try:
            if zone.contains(point):
                candidate_points.append((lon, lat))
        except:
            pass
        
        attempts += 1

    if not candidate_points:
        raise ValueError("æ— æ³•ç”Ÿæˆå€™é€‰è´Ÿæ ·æœ¬ç‚¹")
    
    # è½¬æ¢ä¸ºGeoDataFrameå¹¶å»é‡
    candidate_gdf = gpd.GeoDataFrame(
        {'lon': [p[0] for p in candidate_points], 'lat': [p[1] for p in candidate_points]},
        geometry=gpd.points_from_xy([p[0] for p in candidate_points], [p[1] for p in candidate_points]),
        crs=admin.crs
    ).drop_duplicates(subset=['lon', 'lat'])
    
    # éšæœºæŠ½æ ·å¹¶è¿›è¡Œè·ç¦»æ£€æŸ¥
    np.random.seed(RANDOM_STATE)
    valid_neg = []
    existing_points = valid_pos[['lon', 'lat']].values.tolist()
    candidate_list = candidate_gdf[['lon', 'lat']].values.tolist()
    
    # ä¼˜å…ˆé€‰æ‹©è·ç¦»æ­£æ ·æœ¬è¶³å¤Ÿè¿œçš„ç‚¹
    for pt in candidate_list:
        if check_min_distance([pt], existing_points, MIN_DISTANCE):
            valid_neg.append(pt)
            if len(valid_neg) >= n_neg:
                break
    
    # å¦‚æœå€™é€‰ç‚¹ä¸è¶³ï¼Œæ”¾å®½æ¡ä»¶ï¼ˆå…ˆæ»¡è¶³æ•°é‡å†æ£€æŸ¥è·ç¦»ï¼‰
    if len(valid_neg) < n_neg:
        print(f"è­¦å‘Šï¼šä»…æ‰¾åˆ°{len(valid_neg)}ä¸ªæ»¡è¶³è·ç¦»æ¡ä»¶çš„ç‚¹ï¼Œç›®æ ‡éœ€è¦{n_neg}ä¸ª")
        print(f"å°†è¡¥å……ä¸€äº›è·ç¦»å¯èƒ½ä¸è¶³çš„ç‚¹")
        # è¡¥å……ä¸€äº›ç‚¹ï¼Œå³ä½¿è·ç¦»å¯èƒ½ä¸è¶³
        for pt in candidate_list:
            if pt not in valid_neg:
                valid_neg.append(pt)
                if len(valid_neg) >= n_neg:
                    break
    
    # è½¬æ¢ä¸ºDataFrame - åªåŒ…å«åŸºæœ¬å­—æ®µ
    valid_neg = pd.DataFrame(valid_neg[:n_neg], columns=['lon', 'lat'])  # åªå–éœ€è¦çš„æ•°é‡
    valid_neg['target'] = 0

    # ================= åˆ†é…å®Œå…¨åŒ¹é…çš„æ—¥æœŸ =================
    print(f"   æ­£åœ¨ä¸ºæ­£æ ·æœ¬åˆ†é…å®Œå…¨ç›¸åŒçš„æ—¥æœŸåˆ†å¸ƒ...")
    
    # æ–¹æ³•ï¼šä»æ­£æ ·æœ¬çš„æ—¥æœŸä¸­ç›´æ¥æŠ½æ ·ï¼ˆæœ‰æ”¾å›ï¼‰ï¼Œç¡®ä¿æ—¶é—´åˆ†å¸ƒå®Œå…¨ç›¸åŒ
    pos_dates = time_features['date_list']
    
    if len(pos_dates) > 0:
        # ä½¿ç”¨æœ‰æ”¾å›æŠ½æ ·ï¼Œç¡®ä¿è´Ÿæ ·æœ¬æ—¥æœŸåˆ†å¸ƒä¸æ­£æ ·æœ¬å®Œå…¨ç›¸åŒ
        valid_neg['æ—¥æœŸ'] = np.random.choice(pos_dates, size=len(valid_neg), replace=True)
    else:
        raise ValueError("æ­£æ ·æœ¬ä¸­æ²¡æœ‰æœ‰æ•ˆæ—¥æœŸæ•°æ®")
    
    # æ£€æŸ¥æ—¶é—´åˆ†å¸ƒæ˜¯å¦åŒ¹é…
    pos_month_dist = pd.Series([d.month for d in pos_dates]).value_counts(normalize=True).sort_index()
    neg_month_dist = pd.Series([d.month for d in valid_neg['æ—¥æœŸ']]).value_counts(normalize=True).sort_index()
    
    print(f"   æ­£æ ·æœ¬æœˆä»½åˆ†å¸ƒ: {dict(pos_month_dist)}")
    print(f"   è´Ÿæ ·æœ¬æœˆä»½åˆ†å¸ƒ: {dict(neg_month_dist)}")
    
    # ================= åˆ†é…ID =================
    # è´Ÿæ ·æœ¬IDä¸ºè´Ÿæ•°ï¼Œä»-1å¼€å§‹é€’å‡
    valid_neg['id'] = -np.arange(1, len(valid_neg) + 1)
    
    # ================= æ•°æ®åˆå¹¶ =================
    # åªä¿ç•™åŸºæœ¬å­—æ®µ
    basic_cols = ['id', 'lon', 'lat', 'æ—¥æœŸ', 'target']
    
    # ç¡®ä¿æ­£æ ·æœ¬ä¹ŸåªåŒ…å«è¿™äº›å­—æ®µï¼ˆå¦‚æœæœ‰å¤šä½™å­—æ®µï¼‰
    pos_basic = valid_pos[basic_cols].copy() if all(col in valid_pos.columns for col in basic_cols) else valid_pos
    
    # åˆå¹¶æ­£è´Ÿæ ·æœ¬
    balanced = pd.concat([
        pos_basic,
        valid_neg[basic_cols]
    ], ignore_index=True)
    
    # æ‰“ä¹±é¡ºåº
    return balanced.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)


def plot_comparison(original, balanced, admin, vulnerability, save_path, ratio):
    """å¢å¼ºç‰ˆå¯¹æ¯”å¯è§†åŒ–ï¼ˆåŒ…å«æ—¶é—´åˆ†å¸ƒå¯¹æ¯”ï¼‰"""
    # è·å–æ—¶é—´èŒƒå›´
    time_range = ""
    if not original.empty and 'æ—¥æœŸ' in original:
        try:
            min_date = original['æ—¥æœŸ'].min().strftime('%Y-%m-%d')
            max_date = original['æ—¥æœŸ'].max().strftime('%Y-%m-%d')
            time_range = f"{min_date} è‡³ {max_date}"
        except AttributeError:
            time_range = "æ—¥æœŸæ ¼å¼é”™è¯¯"
    
    # è®¡ç®—å®é™…æ¯”ä¾‹
    orig_pos = original[original['target']==1]
    orig_neg = original[original['target']==0]
    bal_pos = balanced[balanced['target']==1]
    bal_neg = balanced[balanced['target']==0]
    actual_ratio = len(bal_neg)/len(bal_pos) if len(bal_pos) > 0 else 0
    
    # åˆ›å»ºæ ‡é¢˜
    main_title = f"æ»‘å¡é£é™©æ ·æœ¬æ—¶ç©ºå¹³è¡¡å¯¹æ¯”ï¼ˆæ—¶é—´å®Œå…¨åŒ¹é…ï¼‰\næ—¶é—´èŒƒå›´: {time_range}\nç›®æ ‡æ¯”ä¾‹ 1:{ratio} | å®é™…æ¯”ä¾‹ 1:{actual_ratio:.1f}"

    # ç»Ÿä¸€åæ ‡ç³»ä¸ºWGS84
    target_crs = "EPSG:4326"
    admin = admin.to_crs(target_crs)
    vulnerability = vulnerability.to_crs(target_crs)

    # åˆ›å»ºå›¾å½¢ - 2è¡Œ2åˆ—å¸ƒå±€
    fig = plt.figure(figsize=(20, 16), dpi=150)
    gs = fig.add_gridspec(2, 2, height_ratios=[1.2, 1])
    
    # ç©ºé—´åˆ†å¸ƒå­å›¾
    ax1 = fig.add_subplot(gs[0, 0], projection=ccrs.PlateCarree())
    ax2 = fig.add_subplot(gs[0, 1], projection=ccrs.PlateCarree())
    
    # æ—¶é—´åˆ†å¸ƒå­å›¾
    ax3 = fig.add_subplot(gs[1, 0])
    ax4 = fig.add_subplot(gs[1, 1])

    # è·å–å®‰å…¨ç»˜å›¾èŒƒå›´
    x_range, y_range = get_safe_plot_range(admin)

    # --- ç»˜åˆ¶åŸå§‹ç©ºé—´åˆ†å¸ƒ ---
    plot_base_map(
        ax=ax1,
        admin=admin,
        vulnerability=vulnerability,
        x_range=x_range,
        y_range=y_range,
        show_yf_legend=False
    )
    plot_samples(ax1, orig_neg, 'blue', 'è´Ÿæ ·æœ¬')
    plot_samples(ax1, orig_pos, 'red', 'æ­£æ ·æœ¬')
    ax1.set_title(f"åŸå§‹ç©ºé—´åˆ†å¸ƒ (1:{len(orig_neg)/len(orig_pos):.1f})", fontsize=12)

    # --- ç»˜åˆ¶å¹³è¡¡åç©ºé—´åˆ†å¸ƒ ---
    plot_base_map(
        ax=ax2,
        admin=admin,
        vulnerability=vulnerability,
        x_range=x_range,
        y_range=y_range,
        show_yf_legend=True
    )
    plot_samples(ax2, bal_neg, 'blue', 'è´Ÿæ ·æœ¬')
    plot_samples(ax2, bal_pos, 'red', 'æ­£æ ·æœ¬')
    ax2.set_title(f"å¹³è¡¡åç©ºé—´åˆ†å¸ƒ (ç›®æ ‡1:{ratio} | å®é™…1:{actual_ratio:.1f})", fontsize=12)

    # --- ç»˜åˆ¶æ—¶é—´åˆ†å¸ƒå¯¹æ¯” ---
    # æœˆä»½åˆ†å¸ƒå¯¹æ¯”
    if 'æ—¥æœŸ' in bal_pos.columns and 'æ—¥æœŸ' in bal_neg.columns:
        # æå–æœˆä»½
        bal_pos_dates = pd.to_datetime(bal_pos['æ—¥æœŸ'])
        bal_neg_dates = pd.to_datetime(bal_neg['æ—¥æœŸ'])
        
        # è·å–æ‰€æœ‰å‡ºç°çš„æœˆä»½
        all_months = sorted(set(bal_pos_dates.dt.month).union(set(bal_neg_dates.dt.month)))
        
        if all_months:
            pos_month_counts = [len(bal_pos_dates[bal_pos_dates.dt.month == m]) for m in all_months]
            neg_month_counts = [len(bal_neg_dates[bal_neg_dates.dt.month == m]) for m in all_months]
            
            # æœˆä»½æ ‡ç­¾æ˜ å°„
            month_labels_map = {
                1: '1æœˆ', 2: '2æœˆ', 3: '3æœˆ', 4: '4æœˆ', 5: '5æœˆ', 6: '6æœˆ',
                7: '7æœˆ', 8: '8æœˆ', 9: '9æœˆ', 10: '10æœˆ', 11: '11æœˆ', 12: '12æœˆ'
            }
            month_labels = [month_labels_map.get(m, f'{m}æœˆ') for m in all_months]
            
            width = 0.35
            x_positions = np.arange(len(all_months))
            ax3.bar(x_positions - width/2, pos_month_counts, width, 
                    label='æ­£æ ·æœ¬', color='red', alpha=0.7)
            ax3.bar(x_positions + width/2, neg_month_counts, width, 
                    label='è´Ÿæ ·æœ¬', color='blue', alpha=0.7)
            ax3.set_xlabel('æœˆä»½')
            ax3.set_ylabel('æ ·æœ¬æ•°')
            ax3.set_title('æ­£è´Ÿæ ·æœ¬æœˆä»½åˆ†å¸ƒå¯¹æ¯”')
            ax3.set_xticks(x_positions)
            ax3.set_xticklabels(month_labels, rotation=45)
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            
            # è®¡ç®—å¹¶æ˜¾ç¤ºåŒ¹é…åº¦
            total_pos = sum(pos_month_counts)
            total_neg = sum(neg_month_counts)
            
            # è®¡ç®—åˆ†å¸ƒç›¸ä¼¼åº¦
            pos_props = [c/total_pos for c in pos_month_counts]
            neg_props = [c/total_neg for c in neg_month_counts]
            mse = np.mean([(p-n)**2 for p, n in zip(pos_props, neg_props)])
            
            # åœ¨å›¾ä¸Šæ·»åŠ åŒ¹é…åº¦æ–‡æœ¬
            ax3.text(0.02, 0.95, f'åˆ†å¸ƒMSE: {mse:.4f}', transform=ax3.transAxes, 
                    fontsize=10, verticalalignment='top', 
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        else:
            ax3.text(0.5, 0.5, 'æ— æœˆä»½æ•°æ®', ha='center', va='center')
            ax3.set_title('æœˆä»½åˆ†å¸ƒå¯¹æ¯”')
    
    # å¹´ä»½åˆ†å¸ƒå¯¹æ¯”
    if 'æ—¥æœŸ' in bal_pos.columns and 'æ—¥æœŸ' in bal_neg.columns:
        bal_pos_dates = pd.to_datetime(bal_pos['æ—¥æœŸ'])
        bal_neg_dates = pd.to_datetime(bal_neg['æ—¥æœŸ'])
        
        all_years = sorted(set(bal_pos_dates.dt.year).union(set(bal_neg_dates.dt.year)))
        
        if all_years:
            pos_year_counts = [len(bal_pos_dates[bal_pos_dates.dt.year == y]) for y in all_years]
            neg_year_counts = [len(bal_neg_dates[bal_neg_dates.dt.year == y]) for y in all_years]
            
            width = 0.35
            x_positions = np.arange(len(all_years))
            ax4.bar(x_positions - width/2, pos_year_counts, width, 
                    label='æ­£æ ·æœ¬', color='red', alpha=0.7)
            ax4.bar(x_positions + width/2, neg_year_counts, width, 
                    label='è´Ÿæ ·æœ¬', color='blue', alpha=0.7)
            ax4.set_xlabel('å¹´ä»½')
            ax4.set_ylabel('æ ·æœ¬æ•°')
            ax4.set_title('æ­£è´Ÿæ ·æœ¬å¹´ä»½åˆ†å¸ƒå¯¹æ¯”')
            ax4.set_xticks(x_positions)
            ax4.set_xticklabels([str(y) for y in all_years], rotation=45)
            ax4.legend()
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(0.5, 0.5, 'æ— å¹´ä»½æ•°æ®', ha='center', va='center')
            ax4.set_title('å¹´ä»½åˆ†å¸ƒå¯¹æ¯”')
    
    # --- å…¨å±€è®¾ç½® ---
    plt.suptitle(main_title, fontsize=14, y=0.98)
    plt.tight_layout()

    # ä¿å­˜å›¾åƒ
    try:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")
        plt.close()


def plot_base_map(ax, admin, vulnerability, x_range, y_range, show_yf_legend):
    """ç»˜åˆ¶åº•å›¾ï¼ˆå«æ˜“å‘æ€§æŒ‡æ•°ï¼‰"""
    # æ˜“å‘æ€§æŒ‡æ•°é¢œè‰²æ˜ å°„ï¼ˆ1-3çº§ï¼‰
    yf_colors = {
        1: '#B4E8D8',  # ä½æ˜“å‘
        2: '#F9D56E',  # ä¸­æ˜“å‘ 
        3: '#F38181'   # é«˜æ˜“å‘
    }
    yf_labels = {
        1: 'ä½æ˜“å‘åŒº',
        2: 'ä¸­æ˜“å‘åŒº', 
        3: 'é«˜æ˜“å‘åŒº'
    }
    # ç»˜åˆ¶æ˜“å‘æ€§æŒ‡æ•°ï¼ˆæŒ‰ç­‰çº§æ’åºç¡®ä¿å›¾ä¾‹é¡ºåºä¸€è‡´ï¼‰
    for yf_class in sorted(vulnerability['fenji'].unique()):
        if yf_class in yf_colors:  # åªå¤„ç†1-3çº§
            layer = vulnerability[vulnerability['fenji'] == yf_class]
            layer.plot(ax=ax, color=yf_colors[yf_class], 
                      edgecolor='none', alpha=0.7,
                      label=yf_labels[yf_class])

    # è¡Œæ”¿è¾¹ç•Œ
    admin.plot(ax=ax, color='none', edgecolor='black', linewidth=0.8, zorder=10)
    
    # æ˜“å‘æ€§å›¾ä¾‹ï¼ˆä»…å³ä¾§å­å›¾æ˜¾ç¤ºï¼‰
    if show_yf_legend:
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor=yf_colors[i], edgecolor='none', label=yf_labels[i])
            for i in sorted(yf_colors.keys())
        ]
        # æ˜¾å¼ä¼ é€’å›¾ä¾‹å‚æ•°
        ax.legend(
            handles=legend_elements,
            title='æ»‘å¡æ˜“å‘æ€§ç­‰çº§',
            loc='lower right',
            framealpha=1,
            fontsize=9
        )
    
    # è®¾ç½®èŒƒå›´
    ax.set_xlim(x_range)
    ax.set_ylim(y_range)
    ax.set_aspect('auto')
    
    # æ·»åŠ åœ°å›¾è¦ç´ 
    ax.add_feature(cfeature.LAND.with_scale('10m'), facecolor='none', edgecolor='gray', alpha=0.3)
    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5)
    gl.top_labels = False
    gl.right_labels = False


def plot_samples(ax, data, color, label):
    """ç»˜åˆ¶æ ·æœ¬ç‚¹"""
    if not data.empty:
        # æ·»åŠ æ ‡ç­¾è¿‡æ»¤é€»è¾‘
        plot_label = label if label not in ['_nolegend_', ''] else None
        marker = '^' if 'æ­£' in label else 'o'
        
        # ä½¿ç”¨matplotlibåŸç”Ÿç»˜å›¾æ–¹å¼
        ax.scatter(
            data['lon'], 
            data['lat'],
            c=color,
            s=40 if 'æ­£' in label else 20,
            marker='^' if 'æ­£' in label else 'o',
            edgecolors='white',
            linewidths=0.8,
            label=plot_label,  # å¯èƒ½ä¸ºNone
            zorder=5,
            transform=ccrs.PlateCarree()
        )
        
        # åˆ›å»ºè‡ªå®šä¹‰å›¾ä¾‹å¥æŸ„
        handle = plt.Line2D(
            [0], [0],
            marker=marker,
            color='w',
            markerfacecolor=color,
            markersize=10,
            markeredgecolor='white'
        )
        ax.legend(
            handles=[handle],
            labels=[f'{label} (n={len(data)})'],
            loc='upper left',
            framealpha=1,
            fontsize=10
        )


def get_safe_plot_range(admin_gdf, padding_ratio=0.15):
    """è·å–å®‰å…¨ç»˜å›¾èŒƒå›´"""
    bounds = admin_gdf.total_bounds
    x_min, y_min, x_max, y_max = bounds
    
    # å¤„ç†å¼‚å¸¸èŒƒå›´
    width = max(x_max - x_min, 0.02)  # æœ€å°çº¦2å…¬é‡Œ
    height = max(y_max - y_min, 0.02)
    
    padding = max(width, height) * padding_ratio
    return (x_min - padding, x_max + padding), (y_min - padding, y_max + padding)


# ---------------------------- ä¸»æµç¨‹ ----------------------------
def main():
    print("=== æ»‘å¡é¢„æµ‹æ ·æœ¬å¹³è¡¡ç³»ç»Ÿï¼ˆæ—¶é—´å®Œå…¨åŒ¹é…ç‰ˆï¼‰===")
    print(f"ç›®æ ‡æ¯”ä¾‹åˆ—è¡¨: {[f'1:{r}' for r in TARGET_RATIOS]}\n")
    print("è¯´æ˜ï¼šè´Ÿæ ·æœ¬ä¸æ­£æ ·æœ¬æ—¶é—´åˆ†å¸ƒå®Œå…¨ä¸€è‡´ï¼Œæ¨¡æ‹ŸåŒåœºé™é›¨æ¡ä»¶ä¸‹å¯èƒ½å‘ç”Ÿæ»‘å¡ä¹Ÿå¯èƒ½ä¸å‘ç”Ÿæ»‘å¡çš„æƒ…å†µ")
    
    # æ•°æ®å‡†å¤‡
    data, admin, vulnerability = load_data()
    
    # ç»Ÿä¸€åæ ‡ç³»
    target_crs = "EPSG:4326"
    admin = admin.to_crs(target_crs)
    vulnerability = vulnerability.to_crs(target_crs)
    
    # ç©ºé—´è¿‡æ»¤
    filtered = filter_in_boundary(data, admin, vulnerability)
    valid_pos = filtered[filtered['target'] == 1]
    orig_neg = filtered[filtered['target'] == 0]
    orig_ratio = len(orig_neg) / len(valid_pos) if len(valid_pos) > 0 else 0
    
    print(f"ğŸ“Œ åˆå§‹æ•°æ®ç»Ÿè®¡:")
    print(f"   æ­£æ ·æœ¬æ•°é‡: {len(valid_pos)}")
    print(f"   è´Ÿæ ·æœ¬æ•°é‡: {len(orig_neg)}")
    print(f"   å½“å‰æ¯”ä¾‹: 1:{orig_ratio:.1f}")
    print(f"   æ•°æ®æ—¶é—´èŒƒå›´: {valid_pos['æ—¥æœŸ'].min()} è‡³ {valid_pos['æ—¥æœŸ'].max()}")
    
    # åˆ†ææ­£æ ·æœ¬æ—¶é—´åˆ†å¸ƒç‰¹å¾
    time_features = analyze_time_distribution(valid_pos)
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs(BASE_DIR, exist_ok=True)
    
    # å¤šæ¯”ä¾‹å¤„ç†
    for ratio in TARGET_RATIOS:
        ratio_str = f"1_{ratio}"
        print(f"\nğŸ”§ æ­£åœ¨å¤„ç†æ¯”ä¾‹ 1:{ratio}...")
        
        try:
            # å¹³è¡¡é‡‡æ ·ï¼ˆæ—¶é—´å®Œå…¨åŒ¹é…ï¼‰
            balanced_data = balance_samples(valid_pos, admin, vulnerability, time_features, ratio)
            
            # æ£€æŸ¥æ ·æœ¬æ•°é‡
            pos_count = len(balanced_data[balanced_data['target']==1])
            neg_count = len(balanced_data[balanced_data['target']==0])
            print(f"   å¹³è¡¡å: æ­£æ ·æœ¬={pos_count}, è´Ÿæ ·æœ¬={neg_count}")
            
            # è¯¦ç»†æ—¶é—´åŒ¹é…åˆ†æ
            if 'æ—¥æœŸ' in balanced_data.columns:
                pos_dates = pd.to_datetime(balanced_data[balanced_data['target']==1]['æ—¥æœŸ'])
                neg_dates = pd.to_datetime(balanced_data[balanced_data['target']==0]['æ—¥æœŸ'])
                
                # æœˆä»½åˆ†å¸ƒ
                pos_month_counts = pos_dates.dt.month.value_counts().sort_index()
                neg_month_counts = neg_dates.dt.month.value_counts().sort_index()
                
                print(f"\n   æ—¶é—´åŒ¹é…åˆ†æ:")
                print(f"     æ­£æ ·æœ¬æœˆä»½åˆ†å¸ƒ: {dict(pos_month_counts)}")
                print(f"     è´Ÿæ ·æœ¬æœˆä»½åˆ†å¸ƒ: {dict(neg_month_counts)}")
                
                # å¹´ä»½åˆ†å¸ƒ
                pos_year_counts = pos_dates.dt.year.value_counts().sort_index()
                neg_year_counts = neg_dates.dt.year.value_counts().sort_index()
                
                print(f"     æ­£æ ·æœ¬å¹´ä»½åˆ†å¸ƒ: {dict(pos_year_counts)}")
                print(f"     è´Ÿæ ·æœ¬å¹´ä»½åˆ†å¸ƒ: {dict(neg_year_counts)}")
                
                # è®¡ç®—æ—¶é—´åŒ¹é…åº¦
                all_months = sorted(set(pos_month_counts.index).union(set(neg_month_counts.index)))
                pos_month_props = pos_month_counts / pos_month_counts.sum()
                neg_month_props = neg_month_counts / neg_month_counts.sum()
                
                # è®¡ç®—æœˆä»½åˆ†å¸ƒåŒ¹é…åº¦
                match_scores = []
                for month in all_months:
                    pos_prop = pos_month_props.get(month, 0)
                    neg_prop = neg_month_props.get(month, 0)
                    match_score = 1 - abs(pos_prop - neg_prop)
                    match_scores.append(match_score)
                
                avg_match_score = np.mean(match_scores)
                print(f"     æœˆä»½åˆ†å¸ƒå¹³å‡åŒ¹é…åº¦: {avg_match_score:.3f} (1.0è¡¨ç¤ºå®Œå…¨åŒ¹é…)")
            
            # åˆ›å»ºæ¯”ä¾‹ä¸“å±ç›®å½•
            ratio_dir = os.path.join(BASE_DIR, f"ratio_{ratio_str}")
            os.makedirs(ratio_dir, exist_ok=True)
            
            # ä¿å­˜æ•°æ®
            data_path = os.path.join(ratio_dir, f"balanced_ratio_{ratio_str}.csv")
            balanced_data.to_csv(data_path, index=False, encoding='gbk')
            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {data_path}")
            
            # å¯è§†åŒ–
            img_path = os.path.join(ratio_dir, f"comparison_ratio_{ratio_str}.png")
            plot_comparison(
                original=filtered,
                balanced=balanced_data,
                admin=admin,
                vulnerability=vulnerability,
                save_path=img_path,
                ratio=ratio
            )
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ¯”ä¾‹1:{ratio}æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    print(f"\nâœ… æ‰€æœ‰å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {BASE_DIR}")
    
    # æœ€ç»ˆç»Ÿè®¡
    print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    for ratio in TARGET_RATIOS:
        ratio_str = f"1_{ratio}"
        data_path = os.path.join(BASE_DIR, f"ratio_{ratio_str}", f"balanced_ratio_{ratio_str}.csv")
        if os.path.exists(data_path):
            df = pd.read_csv(data_path, encoding='gbk')
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
            pos = df[df['target']==1]
            neg = df[df['target']==0]
            
            print(f"   æ¯”ä¾‹1:{ratio}:")
            print(f"     æ­£æ ·æœ¬={len(pos)}, è´Ÿæ ·æœ¬={len(neg)}, å®é™…æ¯”ä¾‹=1:{len(neg)/len(pos):.1f}")
            print(f"     æ—¶é—´å®Œå…¨åŒ¹é…: æ˜¯")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒçš„æ—¥æœŸ
            common_dates = set(pos['æ—¥æœŸ']).intersection(set(neg['æ—¥æœŸ']))
            print(f"     å…±åŒæ—¥æœŸæ•°é‡: {len(common_dates)} (å æ€»æ—¥æœŸæ•°çš„{len(common_dates)/len(set(pos['æ—¥æœŸ'])):.1%})")


if __name__ == "__main__":
    main()
